{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"1NfDV5_jHcu5f_dic6iNIcFt2NvW0VWKJ","authorship_tag":"ABX9TyPepfPYer0O0GNA61h/UXay"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0RlYdEe71GjP","executionInfo":{"status":"ok","timestamp":1763103010850,"user_tz":-480,"elapsed":20358065,"user":{"displayName":"李梓童","userId":"09523374717047813313"}},"outputId":"d17d9b4e-e511-4a3b-e398-ff880af7a23d"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","\n","Experiment: datascale=s, kernel=linear\n","Training SVM with Interior Point Method...\n","Training 3 binary classifiers...\n","\n","Training classifier 1: classes 0 vs 1\n","Training time: 51.8767 seconds\n","\n","Training classifier 2: classes 0 vs 2\n","Training time: 168.5532 seconds\n","\n","Training classifier 3: classes 1 vs 2\n","Training time: 223.9470 seconds\n","Accuracy: 0.5793, Time: 446.3070s\n","\n","Experiment: datascale=s, kernel=rbf\n","Training SVM with Interior Point Method...\n","Training 3 binary classifiers...\n","\n","Training classifier 1: classes 0 vs 1\n","Training time: 53.4103 seconds\n","\n","Training classifier 2: classes 0 vs 2\n","Training time: 166.6525 seconds\n","\n","Training classifier 3: classes 1 vs 2\n","Training time: 219.6823 seconds\n","Accuracy: 0.5469, Time: 451.6788s\n","\n","Experiment: datascale=s, kernel=poly\n","Training SVM with Interior Point Method...\n","Training 3 binary classifiers...\n","\n","Training classifier 1: classes 0 vs 1\n","Training time: 55.3303 seconds\n","\n","Training classifier 2: classes 0 vs 2\n","Training time: 171.2416 seconds\n","\n","Training classifier 3: classes 1 vs 2\n","stop iteration: 68\n","Training time: 161.0400 seconds\n","Accuracy: 0.5687, Time: 393.8699s\n","\n","Experiment: datascale=m, kernel=linear\n","Training SVM with Interior Point Method...\n","Training 3 binary classifiers...\n","\n","Training classifier 1: classes 0 vs 1\n","Training time: 193.7169 seconds\n","\n","Training classifier 2: classes 0 vs 2\n","Training time: 672.9040 seconds\n","\n","Training classifier 3: classes 1 vs 2\n","Training time: 926.2061 seconds\n","Accuracy: 0.5896, Time: 1794.5769s\n","\n","Experiment: datascale=m, kernel=rbf\n","Training SVM with Interior Point Method...\n","Training 3 binary classifiers...\n","\n","Training classifier 1: classes 0 vs 1\n","Training time: 195.6614 seconds\n","\n","Training classifier 2: classes 0 vs 2\n","Training time: 668.7587 seconds\n","\n","Training classifier 3: classes 1 vs 2\n","Training time: 943.5331 seconds\n","Accuracy: 0.5473, Time: 1822.6228s\n","\n","Experiment: datascale=m, kernel=poly\n","Training SVM with Interior Point Method...\n","Training 3 binary classifiers...\n","\n","Training classifier 1: classes 0 vs 1\n","Training time: 196.3835 seconds\n","\n","Training classifier 2: classes 0 vs 2\n","Training time: 654.8225 seconds\n","\n","Training classifier 3: classes 1 vs 2\n","Training time: 918.6852 seconds\n","Accuracy: 0.5763, Time: 1777.5047s\n","\n","Experiment: datascale=l, kernel=linear\n","Training SVM with Interior Point Method...\n","Training 3 binary classifiers...\n","\n","Training classifier 1: classes 0 vs 1\n","Training time: 476.2350 seconds\n","\n","Training classifier 2: classes 0 vs 2\n","Training time: 1669.9130 seconds\n","\n","Training classifier 3: classes 1 vs 2\n","Training time: 2368.2343 seconds\n","Accuracy: 0.5829, Time: 4517.3597s\n","\n","Experiment: datascale=l, kernel=rbf\n","Training SVM with Interior Point Method...\n","Training 3 binary classifiers...\n","\n","Training classifier 1: classes 0 vs 1\n","Training time: 471.7728 seconds\n","\n","Training classifier 2: classes 0 vs 2\n","Training time: 1666.9872 seconds\n","\n","Training classifier 3: classes 1 vs 2\n","Training time: 2421.5081 seconds\n","Accuracy: 0.5485, Time: 4584.1090s\n","\n","Experiment: datascale=l, kernel=poly\n","Training SVM with Interior Point Method...\n","Training 3 binary classifiers...\n","\n","Training classifier 1: classes 0 vs 1\n","Training time: 476.9595 seconds\n","\n","Training classifier 2: classes 0 vs 2\n","Training time: 1693.4061 seconds\n","\n","Training classifier 3: classes 1 vs 2\n","Training time: 2381.1900 seconds\n","Accuracy: 0.5756, Time: 4562.0442s\n","\n","All experiments completed. Results saved to /content/drive/MyDrive/COMP6704_dataset/result_data.csv\n"]}],"source":["import numpy as np\n","import pandas as pd\n","from sklearn.preprocessing import StandardScaler, LabelEncoder\n","from sklearn.metrics import accuracy_score, classification_report\n","from sklearn.impute import SimpleImputer\n","from sklearn.svm import SVC\n","from sklearn.linear_model import SGDClassifier\n","from sklearn.metrics import classification_report, accuracy_score\n","import matplotlib.pyplot as plt\n","import time\n","import os\n","\n","\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","# convert 'Credit_Mix' to num\n","credit_mix_mapping = {\n","   'Good': 1.0,\n","   'Standard': 0.5,\n","   'Bad': 0.0\n","}\n","\n","# convert 'Credit_History_Age' item to float\n","def convert_to_float(age_str):\n","   if isinstance(age_str, str):\n","       years, months = map(int, age_str.replace('Years and', '').replace('Months', '').split())\n","       return years + months / 12.0\n","   return age_str\n","\n","def compute_kernel(X1, X2, kernel='rbf', gamma=1.0, degree=3, coef0=1.0):\n","    \"\"\"Compute kernel matrix\"\"\"\n","    if kernel == 'linear':\n","        return X1 @ X2.T\n","    elif kernel == 'rbf':\n","        sq_dists = np.sum(X1**2, axis=1, keepdims=True) + np.sum(X2**2, axis=1) - 2 * X1 @ X2.T\n","        return np.exp(-gamma * sq_dists)\n","    elif kernel == 'poly':\n","        return (gamma * X1 @ X2.T + coef0) ** degree\n","    elif kernel == 'sigmoid':\n","        return np.tanh(gamma * X1 @ X2.T + coef0)\n","\n","def interior_point_svm_binary(X, y, C=1.0, kernel='rbf', gamma=1.0, degree=3, coef0=1.0, tol=1e-6, max_iter=100, collect_data=False):\n","    \"\"\"Binary SVM using Interior Point Method with kernel support\"\"\"\n","    start_time = time.time()\n","    n, d = X.shape\n","    K = compute_kernel(X, X, kernel, gamma, degree, coef0)\n","    alpha = np.ones(n) * 0.1\n","    mu = 1.0\n","\n","    residuals, objectives, mus = [], [], []\n","\n","    for iteration in range(max_iter):\n","        barrier_hess = 1/(alpha**2) + 1/((C - alpha)**2)\n","        H = K + mu * np.diag(barrier_hess)\n","        barrier_grad = -1/alpha + 1/(C - alpha)\n","        grad = np.ones(n) - K @ alpha + mu * barrier_grad\n","        delta_alpha = np.linalg.solve(H, -grad)\n","\n","        step_size = 1.0\n","        while np.any(alpha + step_size * delta_alpha <= 0) or \\\n","            np.any(alpha + step_size * delta_alpha >= C):\n","            step_size *= 0.5\n","            if step_size < 1e-10:\n","                break\n","\n","        alpha += step_size * delta_alpha\n","        alpha = np.clip(alpha, 1e-10, C - 1e-10)\n","\n","        residual = np.linalg.norm(delta_alpha)\n","        objective = 0.5 * np.sum(alpha * (K @ alpha)) - np.sum(alpha)\n","\n","        residuals.append(residual)\n","        objectives.append(objective)\n","        mus.append(mu)\n","\n","        mu *= 0.9\n","\n","        if residual < tol:\n","            print('stop iteration:', iteration)\n","            break\n","\n","    # For non-linear kernels, store alpha and support vectors\n","    support_idx = (alpha > 1e-6) & (alpha < C - 1e-6)\n","    if kernel == 'linear':\n","        w = X.T @ (alpha * y)\n","        b = np.mean(y[support_idx] - X[support_idx] @ w) if np.any(support_idx) else 0\n","        training_time = time.time() - start_time\n","\n","        return w, b, training_time, (residuals, objectives, mus) if collect_data else (w, b, training_time)\n","    else:\n","        # For non-linear kernels, compute bias using support vectors\n","        if np.any(support_idx):\n","            K_sv = compute_kernel(X[support_idx], X, kernel, gamma, degree, coef0)\n","            b = np.mean(y[support_idx] - np.sum((alpha * y) * K_sv, axis=1))\n","        else:\n","            b = 0\n","        # Return alpha, X, y for prediction\n","        model = {'alpha': alpha, 'X': X, 'y': y, 'b': b, 'kernel': kernel, 'gamma': gamma, 'degree': degree, 'coef0': coef0}\n","\n","    training_time = time.time() - start_time\n","\n","    if collect_data:\n","        return model, training_time, (residuals, objectives, mus)\n","    return model, training_time\n","\n","def predict_nonlinear(X_test, model):\n","    \"\"\"Predict using non-linear SVM model\"\"\"\n","    K_test = compute_kernel(X_test, model['X'], model['kernel'], model['gamma'], model['degree'], model['coef0'])\n","    return np.sign(np.sum((model['alpha'] * model['y']) * K_test, axis=1) + model['b'])\n","\n","def multiclass_svm_ovo(X_train, y_train, X_test, classes, C=1.0, kernel='rbf', gamma=1.0, degree=3, coef0=1.0, datascale='', data_folder = ''):\n","    \"\"\"One-vs-One multiclass SVM\"\"\"\n","    n_classes = len(classes)\n","    classifiers = {}\n","    all_residuals = []\n","    labels = []\n","\n","    print(f\"Training {n_classes*(n_classes-1)//2} binary classifiers...\")\n","\n","    # Train binary classifiers for each pair\n","    classifier_count = 0\n","    for i in range(n_classes):\n","        for j in range(i+1, n_classes):\n","            classifier_count += 1\n","            print(f\"\\nTraining classifier {classifier_count}: classes {classes[i]} vs {classes[j]}\")\n","\n","            # Get samples for classes i and j\n","            mask = (y_train == classes[i]) | (y_train == classes[j])\n","            X_pair = X_train[mask]\n","            y_pair = y_train[mask]\n","            y_binary = np.where(y_pair == classes[i], 1, -1)\n","\n","            # Train binary classifier and collect convergence data\n","            if kernel == 'linear':\n","                w, b, train_time, (residuals, objectives, mus) = interior_point_svm_binary(X_pair, y_binary, C, kernel, gamma, degree, coef0, collect_data=True)\n","                classifiers[(i, j)] = (w, b)\n","            else:\n","                model, train_time, (residuals, objectives, mus) = interior_point_svm_binary(X_pair, y_binary, C, kernel, gamma, degree, coef0, collect_data=True)\n","                classifiers[(i, j)] = model\n","            print(f\"Training time: {train_time:.4f} seconds\")\n","            all_residuals.append((residuals, objectives, mus))\n","            labels.append(f\"Class {classes[i]} vs {classes[j]}\")\n","\n","    # Plot all convergence curves in one figure\n","    fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(18, 5))\n","\n","    for (residuals, objectives, mus), label in zip(all_residuals, labels):\n","        ax1.semilogy(residuals, label=label)\n","        ax2.plot(objectives, label=label)\n","        ax3.semilogy(mus, label=label)\n","\n","    ax1.set_title('Residual Convergence')\n","    ax1.set_xlabel('Iteration')\n","    ax1.set_ylabel('Residual (log scale)')\n","    ax1.legend()\n","    ax1.grid(True)\n","\n","    ax2.set_title('Objective Function of the Dual Problem')\n","    ax2.set_xlabel('Iteration')\n","    ax2.set_ylabel('Objective Value')\n","    ax2.legend()\n","    ax2.grid(True)\n","\n","    ax3.set_title('Barrier Parameter (Mu)')\n","    ax3.set_xlabel('Iteration')\n","    ax3.set_ylabel('Mu (log scale)')\n","    ax3.legend()\n","    ax3.grid(True)\n","\n","    plt.tight_layout()\n","    plt.savefig(f'{data_folder}all_classifiers_convergence_{kernel}_{datascale}.png', dpi=150, bbox_inches='tight')\n","    plt.close()\n","\n","    # Predict using voting\n","    predictions = []\n","    for x in X_test:\n","        votes = np.zeros(n_classes)\n","        for (i, j), classifier in classifiers.items():\n","            if kernel == 'linear':\n","                w, b = classifier\n","                pred = np.sign(x @ w + b)\n","            else:\n","                pred = predict_nonlinear(x.reshape(1, -1), classifier)[0]\n","            if pred > 0:\n","                votes[i] += 1\n","            else:\n","                votes[j] += 1\n","        predictions.append(classes[np.argmax(votes)])\n","\n","    return np.array(predictions)\n","\n","\n","def processing_train_test(train_data, test_data):\n","    train_data['Credit_History_Age'] = train_data['Credit_History_Age'].apply(convert_to_float)\n","    test_data['Credit_History_Age'] = test_data['Credit_History_Age'].apply(convert_to_float)\n","    train_data['Credit_Mix'] = train_data['Credit_Mix'].map(credit_mix_mapping)\n","    test_data['Credit_Mix'] = test_data['Credit_Mix'].map(credit_mix_mapping)\n","    # convert 'Payment_Behaviour' to num\n","    unique_behaviors = train_data['Payment_Behaviour'].unique()\n","    behavior_mapping = {behavior: idx for idx, behavior in enumerate(unique_behaviors)}\n","    train_data['Payment_Behaviour'] = train_data['Payment_Behaviour'].map(behavior_mapping)\n","    test_data['Payment_Behaviour'] = test_data['Payment_Behaviour'].map(behavior_mapping)\n","\n","    train_data = train_data.dropna()\n","    test_data = test_data.dropna()\n","\n","    # feature selection\n","    features = ['Age', 'Annual_Income', 'Monthly_Inhand_Salary', 'Num_Bank_Accounts',\n","            'Num_Credit_Card', 'Interest_Rate', 'Num_of_Loan', 'Delay_from_due_date',\n","            'Num_of_Delayed_Payment', 'Changed_Credit_Limit', 'Num_Credit_Inquiries',\n","            'Credit_Mix', 'Outstanding_Debt', 'Credit_Utilization_Ratio', 'Credit_History_Age',\n","                'Amount_invested_monthly', 'Monthly_Balance', 'Payment_Behaviour']\n","\n","    X_train = train_data[features]\n","    y_train = train_data['Credit_Score']\n","    X_test = test_data[features]\n","    y_test = test_data['Credit_Score']\n","\n","    # convert label to num: good->2, standard->1, poor->0\n","    le = LabelEncoder()\n","    y_train = le.fit_transform(y_train)\n","    y_test = le.transform(y_test)\n","\n","    scaler = StandardScaler()\n","    X_train = scaler.fit_transform(X_train)\n","    X_test = scaler.transform(X_test)\n","\n","    return X_train, y_train, X_test, y_test\n","\n","# Preprocess function\n","def preprocess_data(df):\n","    df = df.drop(['ID', 'Customer_ID'], axis=1)\n","    df['Name'].fillna('Unknown', inplace=True)\n","    df['Occupation'].fillna('Unknown', inplace=True)\n","    df['SSN'] = df['SSN'].replace('#F%$D@*&8', np.nan)\n","    df['SSN'].fillna('000-00-0000', inplace=True)\n","    df['Num_of_Loan'] = df['Num_of_Loan'].replace(-100, 0)\n","    df['Interest_Rate'] = df['Interest_Rate'].replace(-100, df['Interest_Rate'].median())\n","    return df\n","\n","\n","def run_svm_experiment(datascale='s', kernel='rbf', data_folder='/home/zitong/COMP6704/dataset/', C=1.0, gamma=0.1, degree=3, coef0=1.0):\n","    \"\"\"Run SVM experiment with given parameters\"\"\"\n","    # Read data\n","    train_data_path = f'{data_folder}train_data_{datascale}.csv'\n","    test_data_path = f'{data_folder}test_data.csv'\n","    result_data_path = f'{data_folder}result_data.csv'\n","\n","    train_data = pd.read_csv(train_data_path)\n","    test_data = pd.read_csv(test_data_path)\n","\n","    print(f'\\nExperiment: datascale={datascale}, kernel={kernel}')\n","\n","    X_train, y_train, X_test, y_test = processing_train_test(train_data, test_data)\n","    classes = np.unique(y_train)\n","\n","    # Train SVM\n","    print(\"Training SVM with Interior Point Method...\")\n","    total_start_time = time.time()\n","    y_pred = multiclass_svm_ovo(X_train, y_train, X_test, classes, C, kernel, gamma, degree, coef0, datascale, data_folder)\n","    total_time = time.time() - total_start_time\n","\n","    # Evaluate\n","    accuracy = accuracy_score(y_test, y_pred)\n","    print(f\"Accuracy: {accuracy:.4f}, Time: {total_time:.4f}s\")\n","\n","    # Save results\n","    results_df = pd.DataFrame({\n","        'datascale': [datascale],\n","        'kernel': [kernel],\n","        'timing': [total_time],\n","        'accuracy': [accuracy]\n","    })\n","    results_df.to_csv(result_data_path, mode='a', header=not os.path.exists(result_data_path), index=False)\n","\n","    return accuracy, total_time\n","\n","# Run experiments\n","data_folder = '/content/drive/MyDrive/COMP6704_dataset/'  # Change this path as needed\n","for datascale in ['s', 'm', 'l']:\n","    for kernel in ['linear', 'rbf', 'poly']:\n","        run_svm_experiment(datascale, kernel, data_folder)\n","\n","print(f\"\\nAll experiments completed. Results saved to {data_folder}result_data.csv\")\n"]}]}